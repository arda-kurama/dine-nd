name: DineND Daily Update + Embed

on:
    schedule:
        - cron: "0 6 * * *" # 2 AM EDT
    workflow_dispatch:

jobs:
    scrape-embed-push:
        runs-on: ubuntu-latest

        steps:
            # 1. Check out main branch and run scraper
            - uses: actions/checkout@v3
              with:
                  ref: main
                  fetch-depth: 0

            - name: Set up Python 3.12 with pip caching
              uses: actions/setup-python@v4
              with:
                  python-version: "3.12"
                  cache: pip
                  cache-dependency-path: requirements.txt

            - name: Install Chromium + Chromedriver manually (no snap)
              run: |
                  sudo apt-get update
                  sudo apt-get install -y wget unzip xvfb libnss3 libxi6 libatk1.0-0 libgtk-3-0 libxss1 libasound2t64
                  wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chrome-linux64.zip
                  unzip chrome-linux64.zip
                  sudo mv chrome-linux64 /opt/chrome
                  sudo ln -s /opt/chrome/chrome /usr/bin/chromium-browser

                  wget https://storage.googleapis.com/chrome-for-testing-public/122.0.6261.94/linux64/chromedriver-linux64.zip
                  unzip chromedriver-linux64.zip
                  sudo mv chromedriver-linux64/chromedriver /usr/bin/chromedriver
                  sudo chmod +x /usr/bin/chromedriver

                  chromedriver --version
                  chromium-browser --version

            - name: Install Python dependencies
              run: |
                  pip install --upgrade pip
                  pip install -r requirements.txt

            - name: Run the dining-hall scraper
              run: |
                  python -m backend.main
                  mkdir -p /tmp/menu_json
                  mv menu_summary.json /tmp/menu_json/menu_summary.json
                  mv consolidated_menu.json /tmp/menu_json/consolidated_menu.json

            # 2. Check out backend-deployment branch and push scraped JSON
            - name: Checkout backend-deployment
              uses: actions/checkout@v3
              with:
                  ref: backend-deployment
                  fetch-depth: 0
                  persist-credentials: true

            - name: Copy JSON into backend-deployment
              run: |
                  cp /tmp/menu_json/menu_summary.json ./menu_summary.json
                  cp /tmp/menu_json/consolidated_menu.json ./consolidated_menu.json

            - name: Commit & push updated JSON
              run: |
                  git add menu_summary.json consolidated_menu.json
                  if ! git diff --cached --quiet; then
                    git config user.name "github-actions[bot]"
                    git config user.email "github-actions[bot]@users.noreply.github.com"
                    git commit -m "ci: daily menu update $(date -u +'%Y-%m-%d')"
                    git push origin backend-deployment
                  else
                    echo "No changes to JSON on backend-deploymentâ€”skipping commit."

            # 3. Embed to Pinecone using latest backend JSON
            - name: Run embed & upsert to Pinecone
              env:
                  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
                  PINECONE_API_KEY: ${{ secrets.PINECONE_API_KEY }}
                  PINECONE_ENV: ${{ secrets.PINECONE_ENV }}
              run: python plate_planner/embed_menu.py consolidated_menu.json
